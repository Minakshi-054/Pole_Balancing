{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 05:04:43.765651: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat\n",
    "import random\n",
    "import math\n",
    "from numpy import genfromtxt\n",
    "import resampy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /home/Students/stg60/miniconda3/envs/tf_gpu_27/lib/python3.9/site-packages (0.11.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/Students/stg60/miniconda3/envs/tf_gpu_27/lib/python3.9/site-packages (from seaborn) (1.4.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/Students/stg60/miniconda3/envs/tf_gpu_27/lib/python3.9/site-packages (from seaborn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/Students/stg60/miniconda3/envs/tf_gpu_27/lib/python3.9/site-packages (from seaborn) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/Students/stg60/miniconda3/envs/tf_gpu_27/lib/python3.9/site-packages (from seaborn) (1.19.5)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /home/Students/stg60/miniconda3/envs/tf_gpu_27/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (6.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/Students/stg60/miniconda3/envs/tf_gpu_27/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/Students/stg60/miniconda3/envs/tf_gpu_27/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/Students/stg60/miniconda3/envs/tf_gpu_27/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/Students/stg60/miniconda3/envs/tf_gpu_27/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/Students/stg60/miniconda3/envs/tf_gpu_27/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/Students/stg60/miniconda3/envs/tf_gpu_27/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (4.28.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/Students/stg60/miniconda3/envs/tf_gpu_27/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/Students/stg60/miniconda3/envs/tf_gpu_27/lib/python3.9/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/Students/stg60/miniconda3/envs/tf_gpu_27/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /home/Students/stg60/miniconda3/envs/tf_gpu_27/lib/python3.9/site-packages (from setuptools-scm>=4->matplotlib>=2.2->seaborn) (1.2.2)\n",
      "Requirement already satisfied: setuptools in /home/Students/stg60/miniconda3/envs/tf_gpu_27/lib/python3.9/site-packages (from setuptools-scm>=4->matplotlib>=2.2->seaborn) (58.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path(\"/data/stg60/milton_plotdata/test/\")\n",
    "#data_milton_par = Path(\"/data/stg60/milton_plotdata/Milton_for_parameter_est/\")\n",
    "data_milton_par = Path(\"/data/stg60/milton_plotdata/test/\")\n",
    "data_milton_pred=Path(\"/data/stg60/milton_plotdata/Milton_for_prediction/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strides(a, L = 128, S=1):  # Window len = L, Stride len/stepsize = S\n",
    "    tolist = False\n",
    "    if isinstance(a, list):\n",
    "        tolist = True\n",
    "        a = np.array(a)\n",
    "    if S is None:\n",
    "        S = math.ceil(a.size/10)\n",
    "    nrows = ((a.size - L) // S) + 1\n",
    "    n = a.strides[0]\n",
    "    #print(n)\n",
    "    windows = np.lib.stride_tricks.as_strided(a, shape=(nrows, L), strides=(S * n, n))\n",
    "    \n",
    "    if tolist:\n",
    "        windows = windows.tolist()\n",
    "    return windows\n",
    "def read_tsv(tsv, start_index = 1024, end_index = None, scale = True):\n",
    "    dat = genfromtxt(tsv, delimiter='\\t')\n",
    "    x1,x2,x3,x4,x5,x6 = np.hsplit(dat,6)\n",
    "    ell_1=((x1-x4)**2+(x2-x5)**2+(x3-x6)**2)**0.5 + 1e-10\n",
    "    ang_sin_x_1=(x1-x4)/ell_1\n",
    "    phi =np.arcsin(ang_sin_x_1)*180/np.pi\n",
    "    phi = phi.reshape(-1)[start_index:end_index]\n",
    "    x1 = x1.reshape(-1)[start_index:end_index]\n",
    "    phi = resampy.resample(phi, sr_orig = 250, sr_new = 100)\n",
    "    x1 = resampy.resample(x1, sr_orig = 250, sr_new = 100)\n",
    "    if scale:\n",
    "        phi = phi/20\n",
    "        x1 = x1/0.335\n",
    "    return phi, x1\n",
    "def prepareData(path, cutoff = 128, delay = 23, L = 128, timetopredict = 1.96, samplingrate = 100, fall_stride = 1, start_index = 1024, end_index = None, scale = True):\n",
    "    \"\"\"AI is creating summary for prepareData\n",
    "\n",
    "    Args:\n",
    "        path ([Str]): [path to the original file]\n",
    "        cutoff (int, optional): [description]. Defaults to 128.\n",
    "        delay (int, optional): [description]. Defaults to 23.\n",
    "        L (int, optional): [Window size]. Defaults to 128.\n",
    "        timetopredict (float, optional): [description]. Defaults to 1.96.\n",
    "        samplingrate (int, optional): [description]. Defaults to 100.\n",
    "        fall_stride (int, optional): [description]. Defaults to 1.\n",
    "        start_index (int, optional): [description]. Defaults to 1024.\n",
    "        end_index ([type], optional): [description]. Defaults to None.\n",
    "        scale (bool, optional): [description]. Defaults to True.\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "\n",
    "    Yields:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    # timetopredict in seconds, note 1 point = 0.01 seconds, or 100points = 1seconds\n",
    "    def disect(*args, separator = None):\n",
    "        for arg in args:\n",
    "            nofall, fall = arg[:-separator], arg[-separator:]\n",
    "            yield (nofall, fall)\n",
    "    \n",
    "    if path.suffix == \".mat\":    \n",
    "        if not isinstance(path, str):\n",
    "            path = path.as_posix()\n",
    "        mat = loadmat(path)\n",
    "        phiv = mat['phiv'].reshape(-1)\n",
    "        dxv = mat['dxv'].reshape(-1)\n",
    "        if scale:\n",
    "            phiv = phiv/20\n",
    "            dxv = dxv/0.335\n",
    "    elif path.suffix == \".tsv\":\n",
    "        phiv, dxv = read_tsv(path, start_index = start_index, end_index=end_index)\n",
    "\n",
    "    phiv = phiv[:-cutoff]\n",
    "    dxv = dxv[:-cutoff]\n",
    "\n",
    "    #phiv -> delay, respo\n",
    "    delay_phiv = phiv[delay:]\n",
    "    respo_phiv = phiv[:-delay]\n",
    "\n",
    "    #dxv -> delay, respo\n",
    "    delay_dxv = dxv[delay:]\n",
    "    respo_dxv = dxv[:-delay]\n",
    "\n",
    "    #fall region\n",
    "    fall_region = L + int(timetopredict*samplingrate)\n",
    "    [(n_delay_phiv, f_delay_phiv), (n_respo_phiv, f_respo_phiv)] = disect(delay_phiv, respo_phiv, separator=fall_region)\n",
    "    [(n_delay_dxv, f_delay_dxv), (n_respo_dxv, f_respo_dxv)] = disect(delay_dxv, respo_dxv, separator=fall_region)\n",
    "\n",
    "    if n_delay_phiv.size < f_delay_phiv.size:\n",
    "        S = 1\n",
    "    else:\n",
    "        S = math.ceil((n_delay_phiv.size - f_delay_phiv.size)/(timetopredict*samplingrate+1))\n",
    "\n",
    "    #s=1 for imbalanced\n",
    "    # no_fall_windows(imbalanced)\n",
    "    n_delay_phiv = strides(n_delay_phiv, L = L, S = 2)\n",
    "    n_respo_phiv = strides(n_respo_phiv, L = L, S = 2)\n",
    "    n_delay_dxv = strides(n_delay_dxv, L = L, S = 2)\n",
    "    n_respo_dxv = strides(n_respo_dxv, L = L, S = 2)\n",
    "\n",
    "    # fall_windows\n",
    "    f_delay_phiv = strides(f_delay_phiv, L = L, S = fall_stride)\n",
    "    #f_delay_phiv1 = strides(f_delay_phiv, L = L, S = fall_stride)\n",
    "    f_respo_phiv = strides(f_respo_phiv, L = L, S = fall_stride)\n",
    "    f_delay_dxv = strides(f_delay_dxv, L = L, S = fall_stride)\n",
    "    f_respo_dxv = strides(f_respo_dxv, L = L, S = fall_stride)\n",
    "\n",
    "    # concatenate features\n",
    "    n_x = np.stack((n_delay_phiv,n_respo_phiv,n_delay_dxv,n_respo_dxv), -1)\n",
    "    f_x = np.stack((f_delay_phiv,f_respo_phiv,f_delay_dxv,f_respo_dxv), -1)\n",
    "\n",
    "    n_y = np.zeros(n_x.shape[0]).reshape(-1,1)\n",
    "    f_y = np.ones(f_x.shape[0]).reshape(-1,1)\n",
    "\n",
    "    x = np.concatenate((n_x,f_x), 0)\n",
    "    y = np.concatenate((n_y,f_y), 0)\n",
    "\n",
    "    return x, y,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOneHugeArray(path_list, start_index_list = None, end_index_list = None):\n",
    "    datax = []\n",
    "    datay = []\n",
    "    if start_index_list is None and end_index_list is None:    \n",
    "        for path in tqdm(path_list):\n",
    "            x,y,_,a,b = prepareData(path, cutoff = 128, delay = 23, L = 128, timetopredict = 1.96, samplingrate = 100, fall_stride = 1)\n",
    "            datax.append(x)\n",
    "            datay.append(y)\n",
    "    else:\n",
    "        for path, start_index, end_index in tqdm(zip(path_list, start_index_list, end_index_list)):\n",
    "            x,y,_ = prepareData(path, cutoff = 128, delay = 23, L = 128, timetopredict = 1.96, samplingrate = 100, fall_stride = 1, start_index = start_index, end_index = end_index)\n",
    "            datax.append(x)\n",
    "            datay.append(y)\n",
    "    x = np.concatenate(datax)    \n",
    "    y = np.concatenate(datay)\n",
    "\n",
    "    return x, y\n",
    "def create_Real_Data(data_path_list, mode = \"pred\"):\n",
    "    phi_data=[]\n",
    "    data_path_list = sorted(data_path_list.glob('*.tsv'))\n",
    "    start_index_list = [1024]*len(data_path_list)\n",
    "    end_index_list = [None]*len(data_path_list)\n",
    "    for x in tqdm(data_path_list):\n",
    "        phi,_ = read_tsv(x)\n",
    "        phi_data.append(phi)\n",
    "        plt.plot(phi, label = x.name)\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"plots_{mode}.png\")\n",
    "\n",
    "    x, y,a,b = getOneHugeArray(data_path_list, start_index_list = start_index_list, end_index_list = end_index_list)\n",
    "    # print(x)\n",
    "    # print(\"break\")\n",
    "    # print(y)\n",
    "    # # print(x[204])\n",
    "    # print(\"break\")\n",
    "    # print(y[207])\n",
    "    \n",
    "    \n",
    "    print(x.shape, y.shape, y.sum()/y.size)\n",
    "    np.savez(data_root/f\"{mode}.npz\", x = x, y = y)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllMats(path = \"/data/stg60/milton_plotdata/test/\", sample = None, filter_required = True, L = 128, timetopredict = 1.96, samplingrate = 100):\n",
    "    maxsize = int(timetopredict*samplingrate) + L*4 + 1\n",
    "    data = sorted(Path(path).glob(\"milton*.mat\"))\n",
    "    if sample:\n",
    "        data = random.sample(data, sample)\n",
    "    if filter_required:\n",
    "        data = list(filter(lambda x:loadmat(x)['phiv'].max()>20 and loadmat(x)['phiv'].size>maxsize, data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sampled sim_path_list is  1\n"
     ]
    }
   ],
   "source": [
    "sim_path_list = getAllMats(sample=None)\n",
    "print(\"The sampled sim_path_list is \", len(sim_path_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 41.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of xtrain is (2418, 128, 4), the ratio of fall/nofall : 0.08147229114971051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xtest, ytest = getOneHugeArray(sim_path_list)\n",
    "print(f\"The shape of xtrain is {xtest.shape}, the ratio of fall/nofall : {ytest.sum()/ytest.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_root.mkdir(exist_ok=True)\n",
    "\n",
    "np.savez(data_root/\"testsim1.npz\", x = xtest, y = ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = Path(f\"/data/stg60/milton_plotdata/par.npz\")\n",
    "valpath = Path(f\"/data/stg60/milton_plotdata/val.npz\")\n",
    "testpath = Path(f\"/data/stg60/milton_plotdata/pred5.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_root = f\"/data/stg60/model_train_miltonsim/version_3\"\n",
    "\n",
    "checkpoint_path = f\"{checkpoint_root}/model.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8O4BVg90hY6-",
    "outputId": "94149375-7d56-4315-f426-dee42a1c169d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loading\n",
      "Train Loaded\n",
      "Val Loading\n",
      "Val Loaded\n",
      "Test Loading\n",
      "Test Loaded\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 28\n",
    "SHUFFLE_BUFFER_SIZE = BATCH_SIZE * 128\n",
    "limit=None\n",
    "print('Train Loading')\n",
    "with np.load(trainpath, allow_pickle=True) as data:\n",
    "    train_examples = data['x'][:limit]\n",
    "    train_labels = (data['y'][:limit]).astype(np.int64)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).prefetch(8)\n",
    "print('Train Loaded')\n",
    "\n",
    "print('Val Loading')\n",
    "with np.load(valpath, allow_pickle=True) as data:\n",
    "    val_examples = data['x']\n",
    "    val_labels = (data['y']).astype(np.int64)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_examples, val_labels)).prefetch(8)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "print('Val Loaded')\n",
    "\n",
    "\n",
    "print('Test Loading')\n",
    "with np.load(testpath, allow_pickle=True) as data:\n",
    "    test_examples = data['x']\n",
    "    test_labels = (data['y']).astype(np.int64)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels)).prefetch(8)\n",
    "test_dataset = test_dataset.batch(TEST_BATCH_SIZE)\n",
    "print('Test Loaded')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf_gpu_27')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ea3dc793623f014c9bb8ce0e3bd7d19657e91ab5be10e398374ee9e7e272561"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
